{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "377e337f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -r no_iapp/outputs/fhn3Ppred\n",
    "!python no_iapp/fhn3Ppred.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb12b0fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile conf/config.yaml\n",
    "# Arch\t                        Start Lr\tMax Steps\tDecay Steps\n",
    "# FullyConnectedArch\t        1.00E-03\t1500000\t        15000\t   \n",
    "# FourierNetArch                1.00E-03\t400000\t        7500\t   \n",
    "# ModifiedFourierNetArch \t1.00E-03\t400000\t        7500\t   \n",
    "# SirenArch                     2.00E-05\t500000\t        5000\t   \n",
    "# DGMArch                       1.00E-03        1500000         15000           \n",
    "\n",
    "# WARNING: Setting \"exact_continuity\" to true or setting the arch\n",
    "# as \"ModifiedFourierNetArch\" increases the memory requirements of the \n",
    "# problem. Batchsizes may need to be reduced for such cases.  \n",
    "\n",
    "defaults :\n",
    "  - modulus_default\n",
    "  - arch:\n",
    "      - fully_connected\n",
    "  - scheduler: exponential_lr \n",
    "  - optimizer: adam\n",
    "  - loss: sum\n",
    "  - _self_\n",
    "\n",
    "jit: false\n",
    "\n",
    "\n",
    "training:\n",
    "  rec_results_freq : 5000\n",
    "  rec_constraint_freq: 100000\n",
    "  max_steps : 300000\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0806f5da",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing no_iapp/fhn3Ppred.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile fhn3Ppred.py\n",
    "\n",
    "from modulus.models.fully_connected import FullyConnectedArch\n",
    "from modulus.models.fourier_net import FourierNetArch\n",
    "from modulus.models.siren import SirenArch\n",
    "from modulus.models.modified_fourier_net import ModifiedFourierNetArch\n",
    "from modulus.models.dgm import DGMArch\n",
    "\n",
    "from sympy import Symbol, Eq\n",
    "from sympy import Symbol, Function, Number\n",
    "from modulus.eq.pde import PDE\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import interpolate\n",
    "import modulus\n",
    "from modulus.hydra import instantiate_arch, ModulusConfig\n",
    "from modulus.solver import Solver\n",
    "from modulus.domain import Domain\n",
    "from modulus.geometry.primitives_1d import Point1D\n",
    "from modulus.domain.constraint import (\n",
    "    PointwiseBoundaryConstraint,\n",
    "    PointwiseInteriorConstraint,\n",
    ")\n",
    "from modulus.domain.validator import PointwiseValidator\n",
    "from modulus.key import Key\n",
    "from modulus.node import Node\n",
    "from modulus.eq.pde import PDE\n",
    "from modulus.geometry import Parameterization\n",
    "from sympy import Symbol, Eq, Abs, tanh, Or, And\n",
    "from modulus.utils.io import (\n",
    "    csv_to_dict,\n",
    "    ValidatorPlotter,\n",
    "    InferencerPlotter,\n",
    ")\n",
    "from modulus.solver import SequentialSolver\n",
    "from modulus.domain.monitor import PointwiseMonitor\n",
    "from modulus.models.deeponet import DeepONetArch\n",
    "from modulus.domain.constraint.continuous import DeepONetConstraint\n",
    "from modulus.models.moving_time_window import MovingTimeWindowArch\n",
    "from modulus.domain.monitor import Monitor\n",
    "from modulus.domain.constraint import Constraint\n",
    "from modulus.graph import Graph\n",
    "from modulus.key import Key\n",
    "from modulus.constants import TF_SUMMARY\n",
    "from modulus.distributed import DistributedManager\n",
    "from modulus.utils.io import dict_to_csv, csv_to_dict\n",
    "from modulus.domain.inferencer.pointwise import PointwiseInferencer as PointwiseInferencer\n",
    "from modulus.loss.loss import CausalLossNorm\n",
    "\n",
    "  \n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch.optim import Optimizer\n",
    "from torch.optim.lr_scheduler import _LRScheduler\n",
    "from torch.cuda.amp import GradScaler\n",
    "import torch.nn as nn\n",
    "import torch.cuda.profiler as profiler\n",
    "import torch.distributed as dist\n",
    "from termcolor import colored, cprint\n",
    "from copy import copy\n",
    "from operator import add\n",
    "from omegaconf import DictConfig, OmegaConf\n",
    "import hydra\n",
    "import itertools\n",
    "from collections import Counter\n",
    "from typing import Dict, List, Optional\n",
    "import logging\n",
    "from contextlib import ExitStack\n",
    "from typing import List, Union, Tuple, Callable\n",
    "\n",
    "\n",
    "from modulus.domain.constraint import Constraint\n",
    "from modulus.domain import Domain\n",
    "from modulus.loss.aggregator import Sum\n",
    "from modulus.utils.training.stop_criterion import StopCriterion\n",
    "from modulus.constants import TF_SUMMARY, JIT_PYTORCH_VERSION\n",
    "from modulus.hydra import (\n",
    "    instantiate_optim,\n",
    "    instantiate_sched,\n",
    "    instantiate_agg,\n",
    "    add_hydra_run_path,\n",
    ")\n",
    "from modulus.distributed.manager import DistributedManager\n",
    " \n",
    "\n",
    "    \n",
    "t_max = 50.0\n",
    "n_w=1\n",
    "t_w= t_max/n_w\n",
    "BTZ=2000\n",
    "\n",
    "def print_folder_contents(folder_path):\n",
    "    if not os.path.exists(folder_path):\n",
    "        print(f\"Folder '{folder_path}' does not exist.\")\n",
    "        return\n",
    "\n",
    "    print(f\"Contents of folder '{folder_path}':\")\n",
    "    for item in os.listdir(folder_path):\n",
    "        print(item)\n",
    "\n",
    "def generateExactSolution(t,dt,x0,w0,rate,P,begin,end):\n",
    "    \n",
    "    \n",
    "    n2=int(t/(dt))+2\n",
    "    n = int((end-begin)/(dt*rate))\n",
    "    Sol=np.zeros((n,3))\n",
    "  \n",
    "    Sol2=np.zeros((n2,2))\n",
    "    Sol2[0]=x0,w0\n",
    "    T=0\n",
    "    k=0\n",
    "    while(k<n2-1):\n",
    "        x,w=Sol2[k]\n",
    "        Sol2[k+1]=10*(x*(x-0.4)*(1-x)-w + P)*dt+  x, 0.2*(x*0.2-0.8*w)*dt +w\n",
    " \n",
    "        if ((k*dt==begin or ((k+1)%rate == 0 and k*dt>=begin and k*dt<=end))and T<n):\n",
    "          \n",
    "           \n",
    "            Sol[T] = Sol2[k][0],Sol2[k][1] , k*dt\n",
    "            T=T+1\n",
    "        \n",
    "        k=k+1\n",
    "        if(k*dt > end):\n",
    "            break\n",
    "    return Sol\n",
    "\n",
    "def generateValidator(i,nodes,data_folder=\"../.././validation/\"):\n",
    "    # Read data arrays from CSV files\n",
    "    \n",
    "    print_folder_contents(data_folder)\n",
    "    T = np.load(data_folder + \"T.npy\")\n",
    "    K = np.load(data_folder + \"K.npy\")\n",
    "    U = np.load(data_folder + \"U.npy\")\n",
    "    V = np.load(data_folder + \"V.npy\")\n",
    "    SOLs = np.load(data_folder + \"SOLs.npy\")\n",
    "    SOLw = np.load(data_folder + \"SOLw.npy\")\n",
    "\n",
    "    t = np.expand_dims(T, axis=-1)\n",
    "    k = np.expand_dims(K, axis=-1)\n",
    "    u = np.expand_dims(U, axis=-1)\n",
    "    Solx = np.expand_dims(SOLs, axis=-1)\n",
    "    Solw = np.expand_dims(SOLw, axis=-1)\n",
    "    v = np.expand_dims(V, axis=-1)\n",
    "\n",
    "    print(\"Added validation of shape\", np.shape(Solx))\n",
    "    invar_numpy = {\n",
    "        \"t\": t,\n",
    "        \"K\": k,\n",
    "        \"V\": v,\n",
    "        \"U\": u,\n",
    "    }\n",
    "\n",
    "    outvar_numpy = {\n",
    "        \"x1\": Solx,\n",
    "        \"w\":Solw\n",
    "    }\n",
    "    validator = PointwiseValidator(\n",
    "        nodes=nodes, invar=invar_numpy, true_outvar=outvar_numpy, batch_size=1024,plotter=None\n",
    "    )\n",
    "    return validator\n",
    "\n",
    "\n",
    "\n",
    "def generateDataC(i,nodes,data_folder=\"../.././treino1/\"):\n",
    "    # Read data arrays from CSV files\n",
    "    \n",
    "    print_folder_contents(data_folder)\n",
    "\n",
    "    T = np.load(data_folder + \"T.npy\")\n",
    "    K = np.load(data_folder + \"K.npy\")\n",
    "    U = np.load(data_folder + \"U.npy\")\n",
    "    V = np.load(data_folder + \"V.npy\")\n",
    "    SOLs = np.load(data_folder + \"SOLs.npy\")\n",
    "    SOLw = np.load(data_folder + \"SOLw.npy\")\n",
    "\n",
    "    t = np.expand_dims(T, axis=-1)\n",
    "    k = np.expand_dims(K, axis=-1)\n",
    "    u = np.expand_dims(U, axis=-1)\n",
    "    Solx = np.expand_dims(SOLs, axis=-1)\n",
    "    Solw = np.expand_dims(SOLw, axis=-1)\n",
    "    v = np.expand_dims(V, axis=-1)\n",
    "\n",
    "    invar_numpy = {\n",
    "        \"t\": t,\n",
    "        \"K\": k,\n",
    "        \"V\": v,\n",
    "        \"U\": u,\n",
    "    }\n",
    "    print(\"Added data constraint of shape\", np.shape(Solx))\n",
    "\n",
    "    outvar_numpy = {\n",
    "        \"x1\": Solx,\n",
    "        \"w\":Solw\n",
    "    }\n",
    "    constraint = DeepONetConstraint.from_numpy(\n",
    "        nodes=nodes,\n",
    "        invar=invar_numpy,\n",
    "        outvar=outvar_numpy,\n",
    "        batch_size=BTZ,\n",
    "        lambda_weighting=None\n",
    "    )\n",
    "\n",
    "    return constraint\n",
    "\n",
    "\n",
    "class SpringMass(PDE):\n",
    "    name = \"SpringMass\"\n",
    "\n",
    "    def __init__(self):\n",
    "\n",
    "        t = Symbol(\"t\")\n",
    "        K = Symbol(\"K\")\n",
    "       \n",
    "        input_variables = {\"t\": t,\"K\":K}\n",
    "\n",
    "        x = Function(\"x1\")(*input_variables)\n",
    "        w= Function(\"w\")(*input_variables)\n",
    "        self.equations = {}\n",
    "        self.equations[\"ode_x1\"] =10*(x*(x-0.4)*(1-x)-w) -x.diff(t)\n",
    "        self.equations[\"ode_w\"]  =K*(x*0.2-0.8*w) -w.diff(t)\n",
    "        \n",
    "@modulus.main(config_path=\"conf\", config_name=\"config\")\n",
    "def run(cfg: ModulusConfig) -> None:\n",
    "\n",
    "\n",
    "    # make list of nodes to unroll graph on\n",
    "    sm = SpringMass()\n",
    "    sm.pprint()\n",
    "    #sm_net = FullyConnectedArch(\n",
    "    #    input_keys=[Key(\"t\"), Key(\"K\")],\n",
    "    #    output_keys=[Key(\"x1\")],\n",
    "    #)\n",
    "    #nodes = sm.make_nodes() + [\n",
    "    #    sm_net.make_node(name=\"network\")\n",
    "    #]\n",
    "\n",
    "\n",
    "    \n",
    "    # make list of nodes to unroll graph on\n",
    "    sm = SpringMass()\n",
    "    sm.pprint()\n",
    "    #sm_net = FullyConnectedArch(\n",
    "    #    input_keys=[Key(\"t\"), Key(\"K\")],\n",
    "    #    output_keys=[Key(\"x1\")],\n",
    "    #)\n",
    "    #nodes = sm.make_nodes() + [\n",
    "    #    sm_net.make_node(name=\"network\")\n",
    "    #]\n",
    "\n",
    "    \n",
    "    \n",
    "    flow_net = FullyConnectedArch(\n",
    "            input_keys=[Key(\"t\"), Key(\"U\"),Key(\"V\"),Key(\"K\") ],\n",
    "            output_keys=[Key(\"x1\"),Key(\"w\")],\n",
    "            layer_size=64,\n",
    "            nr_layers=8,\n",
    "        )\n",
    "\n",
    "    \n",
    "\n",
    "    #time_window_net = MovingTimeWindowArch(flow_net, t_w)\n",
    "\n",
    "    nodes = sm.make_nodes() +[flow_net.make_node(name=\"network\")]\n",
    "\n",
    "\n",
    "    for node in nodes:\n",
    "        print(node.__str__())\n",
    "   \n",
    "    # add constraints to solver\n",
    "    # make geometry\n",
    "    geo = Point1D(0)\n",
    "    \n",
    "    t_symbol = Symbol(\"t\")\n",
    "    x_symbol = Symbol(\"x1\")\n",
    "    k_symbol= Symbol(\"K\")\n",
    "    v_symbol= Symbol(\"V\")\n",
    "    u_symbol= Symbol(\"U\")\n",
    "    \n",
    "    time_range = {t_symbol: (0,t_w )}\n",
    "    k_range= {k_symbol:(0.08,0.012)}\n",
    "    v_range= {v_symbol:(0,0.12)}\n",
    "    u_range= {u_symbol:(0,1)}\n",
    "\n",
    "    tr = {t_symbol: (0, t_w)}\n",
    "\n",
    "    # make domain\n",
    "        # make initial condition domain\n",
    "    ic_domain = Domain(\"initial_conditions\")\n",
    "\n",
    "  \n",
    "    # initial conditions\n",
    "    IC = PointwiseBoundaryConstraint(\n",
    "        nodes=nodes,\n",
    "        geometry=geo,\n",
    "        outvar={\"x1\": u_symbol,\"w\":v_symbol},\n",
    "        batch_size=BTZ,\n",
    "        parameterization={**{t_symbol:0},**k_range,**v_range,**u_range},\n",
    "        lambda_weighting={\n",
    "            \"x1\": 1000,# + 1000*x_symbol.diff(t_symbol)*x_symbol.diff(t_symbol),\n",
    "            \"w\": 1000 #+ 1000*x_symbol.diff(t_symbol)*x_symbol.diff(t_symbol)\n",
    "        },\n",
    "        \n",
    "        \n",
    "        quasirandom=True,\n",
    "    )\n",
    "\n",
    "    ic_domain.add_constraint(IC, name=\"IC\")\n",
    "    \n",
    "        # solve over given time period\n",
    "    interior = PointwiseBoundaryConstraint(\n",
    "        nodes=nodes,\n",
    "        geometry=geo,\n",
    "        outvar={\"ode_x1\": 0.0,\"ode_w\":0.0},\n",
    "        batch_size=BTZ,\n",
    "        parameterization={**tr,**k_range,**v_range,**u_range},\n",
    "        #criteria=And(t_symbol > 0, t_symbol < 3),\n",
    "        lambda_weighting={\n",
    "            \"ode_x1\": 100,# + 1000*x_symbol.diff(t_symbol)*x_symbol.diff(t_symbol),\n",
    "            \"ode_w\":100 #+ 1000*x_symbol.diff(t_symbol)*x_symbol.diff(t_symbol)\n",
    "        },\n",
    "        quasirandom=True,\n",
    "    )\n",
    "    ic_domain.add_constraint(interior, name=\"interior\")\n",
    "    \n",
    "    \n",
    "       # solve over given time period\n",
    "    interior2 = PointwiseBoundaryConstraint(\n",
    "        nodes=nodes,\n",
    "        geometry=geo,\n",
    "        outvar={\"ode_x1\": 0.0,\"ode_w\":0.0},\n",
    "        batch_size=BTZ,\n",
    "        parameterization={**tr,**{u_symbol:(0.45,0.65)},**{v_symbol:(0.0,0.12)},**k_range},\n",
    "        #criteria=And(t_symbol > 0, t_symbol < 3),\n",
    "        lambda_weighting={\n",
    "            \"ode_x1\":100,# + 1000*x_symbol.diff(t_symbol)*x_symbol.diff(t_symbol),\n",
    "            \"ode_w\": 100 #+ 1000*x_symbol.diff(t_symbol)*x_symbol.diff(t_symbol)\n",
    "        },\n",
    "        quasirandom=True,\n",
    "    )\n",
    "   #ic_domain.add_constraint(interior2, name=\"interiorTr\")\n",
    "        \n",
    "        \n",
    "    data_folder=\"../.././extrapol/\"\n",
    "    T = np.load(data_folder + \"T.npy\")\n",
    "    K = np.load(data_folder + \"K.npy\")\n",
    "    U = np.load(data_folder + \"U.npy\")\n",
    "    V = np.load(data_folder + \"V.npy\")\n",
    "    SOLs = np.load(data_folder + \"SOLs.npy\")\n",
    "    SOLw = np.load(data_folder + \"SOLw.npy\")\n",
    "\n",
    "    t = np.expand_dims(T, axis=-1)\n",
    "    k = np.expand_dims(K, axis=-1)\n",
    "    u = np.expand_dims(U, axis=-1)\n",
    "    Solx = np.expand_dims(SOLs, axis=-1)\n",
    "    Solw = np.expand_dims(SOLw, axis=-1)\n",
    "    v = np.expand_dims(V, axis=-1)\n",
    "\n",
    "    print(\"Added monitor of shape\", np.shape(Solx))\n",
    "    invar_numpy = {\n",
    "        \"t\": t,\n",
    "        \"K\": k,\n",
    "        \"V\": v,\n",
    "        \"U\": u,\n",
    "        \"True_u\":Solx,\n",
    "        \"True_w\":Solw\n",
    "    }\n",
    "    \n",
    "\n",
    "    \n",
    "    extrapol_val = PointwiseMonitor(\n",
    "         invar_numpy,\n",
    "         output_names=[\"x1\", \"w\"],\n",
    "         metrics={\n",
    "          \n",
    "             \"Extra_error_mean\": lambda var: torch.mean(\n",
    "                \n",
    "                 torch.abs((torch.abs(var[\"True_u\"]) - torch.abs(var[\"x1\"])))\n",
    "             ),\n",
    "             \n",
    "             \"Extra_error_max\": lambda var: torch.max(\n",
    "                \n",
    "                 torch.abs((torch.abs(var[\"True_u\"]) - torch.abs(var[\"x1\"])))\n",
    "             ),\n",
    "         },\n",
    "         nodes=nodes,\n",
    "     )\n",
    "    ic_domain.add_monitor(extrapol_val)\n",
    " \n",
    "    \n",
    "    \n",
    "    print(\"Added monitor of shape\", np.shape(Solx))\n",
    "\n",
    "    \n",
    "    \n",
    "    data_folder=\"../.././interpol/\"\n",
    "    T = np.load(data_folder + \"T.npy\")\n",
    "    K = np.load(data_folder + \"K.npy\")\n",
    "    U = np.load(data_folder + \"U.npy\")\n",
    "    V = np.load(data_folder + \"V.npy\")\n",
    "    SOLs = np.load(data_folder + \"SOLs.npy\")\n",
    "    SOLw = np.load(data_folder + \"SOLw.npy\")\n",
    "\n",
    "    t = np.expand_dims(T, axis=-1)\n",
    "    k = np.expand_dims(K, axis=-1)\n",
    "    u = np.expand_dims(U, axis=-1)\n",
    "    Solx = np.expand_dims(SOLs, axis=-1)\n",
    "    Solw = np.expand_dims(SOLw, axis=-1)\n",
    "    v = np.expand_dims(V, axis=-1)\n",
    "\n",
    "    print(\"Added validation of shape\", np.shape(Solx))\n",
    "    invar_numpy = {\n",
    "        \"t\": t,\n",
    "        \"K\": k,\n",
    "        \"V\": v,\n",
    "        \"U\": u,\n",
    "        \"True_u\":Solx,\n",
    "        \"True_w\":Solw\n",
    "    }\n",
    "    \n",
    "\n",
    "    \n",
    "    interpol_val = PointwiseMonitor(\n",
    "         invar_numpy,\n",
    "         output_names=[\"x1\", \"w\"],\n",
    "         metrics={\n",
    "          \n",
    "             \"Inter_error_mean\": lambda var: torch.mean(\n",
    "                \n",
    "                 torch.abs((torch.abs(var[\"True_u\"]) - torch.abs(var[\"x1\"])))\n",
    "             ),\n",
    "             \n",
    "             \"Inter_error_max\": lambda var: torch.max(\n",
    "                \n",
    "                torch.abs((torch.abs(var[\"True_u\"]) - torch.abs(var[\"x1\"])))\n",
    "             ),\n",
    "         },\n",
    "         nodes=nodes,\n",
    "     )\n",
    "    ic_domain.add_monitor(interpol_val)\n",
    " \n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "    dom=[]\n",
    "    dom.append((1,ic_domain))\n",
    "    print(cfg)\n",
    "    # make solver\n",
    "    #slv = Solver(cfg, domain)\n",
    "    #print(domains)\n",
    "    i=0\n",
    "    for a,d in dom:\n",
    "      #  print(d)\n",
    "      #  print(d.name)\n",
    "#        d.add_inferencer(generateValidator(i,nodes))\n",
    "        d.add_validator(generateValidator(i,nodes))\n",
    "        d.add_constraint(generateDataC(i,nodes,data_folder=\"../.././treino1/\"),\"data1\")\n",
    "       # d.add_constraint(generateDataC(i,nodes,data_folder=\"../.././treino2/\"),\"data2\")\n",
    "        d.add_constraint(generateDataC(i,nodes,data_folder=\"../.././treino3/\"),\"data3\")\n",
    "       \n",
    "\n",
    "        i=i+1\n",
    "    \n",
    "     \n",
    "    slv = SequentialSolver(\n",
    "        cfg,\n",
    "        dom,\n",
    "\n",
    "    )\n",
    "    slv.solve()\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "if __name__ == \"__main__\":\n",
    "    run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
